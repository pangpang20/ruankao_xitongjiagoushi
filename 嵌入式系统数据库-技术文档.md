# Embedded System Databases - Technical Documentation
# 嵌入式系统数据库 - 技术文档

## Table of Contents | 目录

1. [Introduction | 引言](#introduction)
2. [Embedded Database Systems Comparison | 嵌入式数据库系统对比](#comparison)
3. [Architecture and Design | 架构和设计](#architecture)
4. [Implementation Guide | 实施指南](#implementation)
5. [Performance Optimization | 性能优化](#performance)
6. [Data Synchronization | 数据同步](#synchronization)
7. [Security | 安全性](#security)
8. [Power Optimization | 功耗优化](#power)
9. [Platform-Specific Considerations | 平台特定考虑](#platforms)
10. [Real-World Examples | 真实世界示例](#examples)
11. [Testing and Debugging | 测试和调试](#testing)
12. [Best Practices | 最佳实践](#best-practices)

---

## 1. Introduction | 引言

### 1.1 What is an Embedded Database? | 什么是嵌入式数据库？

**Embedded Database** is a database management system designed to run within the address space of an application, rather than as a separate server process. It is optimized for resource-constrained environments with limited CPU, memory, and storage.

**嵌入式数据库**是设计为在应用程序地址空间内运行的数据库管理系统，而不是作为独立的服务器进程。它针对CPU、内存和存储受限的资源受限环境进行了优化。

### 1.2 Key Characteristics | 关键特性

**Advantages**:
- **Zero Configuration**: No separate server installation or administration
- **Small Footprint**: Library size typically < 1MB
- **High Performance**: Direct API calls without network overhead
- **Portability**: Cross-platform support (ARM, x86, MIPS, RISC-V)
- **Reliability**: ACID transactions and crash recovery
- **Serverless**: Embedded in application process

**优点**：
- **零配置**：无需单独的服务器安装或管理
- **小占用空间**：库大小通常< 1MB
- **高性能**：无网络开销的直接API调用
- **可移植性**：跨平台支持（ARM、x86、MIPS、RISC-V）
- **可靠性**：ACID事务和崩溃恢复
- **无服务器**：嵌入在应用程序进程中

**Constraints**:
- **Limited RAM**: Typically 64KB - 512MB
- **Limited Storage**: 256MB - 32GB
- **Power Budget**: Battery-operated devices (mW to W range)
- **CPU Power**: 50MHz - 2GHz, often single-core

**约束**：
- **有限的RAM**：通常64KB - 512MB
- **有限的存储**：256MB - 32GB
- **功耗预算**：电池供电设备（mW到W范围）
- **CPU能力**：50MHz - 2GHz，通常单核

### 1.3 Use Cases | 用例

- **IoT Devices**: Sensor data logging, device configuration
- **物联网设备**：传感器数据记录、设备配置
- **Mobile Applications**: Offline-first apps, local caching
- **移动应用**：离线优先应用、本地缓存
- **Automotive**: ECU data storage, black box recorders
- **汽车**：ECU数据存储、黑匣子记录器
- **Medical Devices**: Patient data, diagnostic results
- **医疗设备**：患者数据、诊断结果
- **Industrial**: PLC configuration, sensor networks
- **工业**：PLC配置、传感器网络
- **Wearables**: Fitness tracking, health monitoring
- **可穿戴设备**：健身跟踪、健康监测

---

## 2. Embedded Database Systems Comparison | 嵌入式数据库系统对比

### 2.1 SQLite

**Description**: The most widely deployed embedded database, used in billions of devices.

**描述**：应用最广泛的嵌入式数据库，在数十亿设备中使用。

**Architecture**:
- **Storage Engine**: B-tree based
- **Transaction Support**: Full ACID with WAL (Write-Ahead Logging)
- **Query Language**: Standard SQL
- **Concurrency**: Multiple readers, single writer
- **Footprint**: ~600KB compiled library

**架构**：
- **存储引擎**：基于B树
- **事务支持**：完整的ACID，带WAL（预写日志）
- **查询语言**：标准SQL
- **并发性**：多读单写
- **占用空间**：约600KB编译库

**Example Usage**:
```c
#include <sqlite3.h>

int main() {
    sqlite3 *db;
    char *err_msg = 0;
    
    // Open database
    int rc = sqlite3_open("sensor_data.db", &db);
    if (rc != SQLITE_OK) {
        fprintf(stderr, "Cannot open database: %s\n", sqlite3_errmsg(db));
        return 1;
    }
    
    // Create table
    const char *sql = "CREATE TABLE IF NOT EXISTS sensors("
                     "id INTEGER PRIMARY KEY AUTOINCREMENT,"
                     "timestamp INTEGER,"
                     "temperature REAL,"
                     "humidity REAL);";
    
    rc = sqlite3_exec(db, sql, 0, 0, &err_msg);
    
    // Insert data
    sql = "INSERT INTO sensors(timestamp, temperature, humidity) "
          "VALUES(?, ?, ?);";
    
    sqlite3_stmt *stmt;
    sqlite3_prepare_v2(db, sql, -1, &stmt, 0);
    sqlite3_bind_int64(stmt, 1, time(NULL));
    sqlite3_bind_double(stmt, 2, 25.5);
    sqlite3_bind_double(stmt, 3, 60.2);
    sqlite3_step(stmt);
    sqlite3_finalize(stmt);
    
    sqlite3_close(db);
    return 0;
}
```

**示例使用**：
```c
#include <sqlite3.h>

int main() {
    sqlite3 *db;
    char *err_msg = 0;
    
    // 打开数据库
    int rc = sqlite3_open("sensor_data.db", &db);
    if (rc != SQLITE_OK) {
        fprintf(stderr, "无法打开数据库: %s\n", sqlite3_errmsg(db));
        return 1;
    }
    
    // 创建表
    const char *sql = "CREATE TABLE IF NOT EXISTS sensors("
                     "id INTEGER PRIMARY KEY AUTOINCREMENT,"
                     "timestamp INTEGER,"
                     "temperature REAL,"
                     "humidity REAL);";
    
    rc = sqlite3_exec(db, sql, 0, 0, &err_msg);
    
    // 插入数据
    sql = "INSERT INTO sensors(timestamp, temperature, humidity) "
          "VALUES(?, ?, ?);";
    
    sqlite3_stmt *stmt;
    sqlite3_prepare_v2(db, sql, -1, &stmt, 0);
    sqlite3_bind_int64(stmt, 1, time(NULL));
    sqlite3_bind_double(stmt, 2, 25.5);
    sqlite3_bind_double(stmt, 3, 60.2);
    sqlite3_step(stmt);
    sqlite3_finalize(stmt);
    
    sqlite3_close(db);
    return 0;
}
```

**Optimization for Embedded Systems**:
```c
// Enable WAL mode for better concurrency
sqlite3_exec(db, "PRAGMA journal_mode=WAL;", 0, 0, 0);

// Reduce memory usage
sqlite3_exec(db, "PRAGMA cache_size=2000;", 0, 0, 0);  // 2000 pages

// Faster writes at expense of durability (for non-critical data)
sqlite3_exec(db, "PRAGMA synchronous=NORMAL;", 0, 0, 0);

// Memory-mapped I/O for read-heavy workloads
sqlite3_exec(db, "PRAGMA mmap_size=268435456;", 0, 0, 0);  // 256MB
```

**嵌入式系统优化**：
```c
// 启用WAL模式以获得更好的并发性
sqlite3_exec(db, "PRAGMA journal_mode=WAL;", 0, 0, 0);

// 减少内存使用
sqlite3_exec(db, "PRAGMA cache_size=2000;", 0, 0, 0);  // 2000页

// 以牺牲持久性为代价加快写入（对于非关键数据）
sqlite3_exec(db, "PRAGMA synchronous=NORMAL;", 0, 0, 0);

// 用于读密集型工作负载的内存映射I/O
sqlite3_exec(db, "PRAGMA mmap_size=268435456;", 0, 0, 0);  // 256MB
```

### 2.2 LevelDB

**Description**: Log-Structured Merge (LSM) tree based key-value store, optimized for write-heavy workloads.

**描述**：基于日志结构合并（LSM）树的键值存储，针对写密集型工作负载优化。

**Architecture**:
- **Storage Engine**: LSM-tree
- **Transaction Support**: Atomic batch writes
- **Query Language**: Key-value API (no SQL)
- **Concurrency**: Single writer, multiple readers
- **Footprint**: ~250KB library

**架构**：
- **存储引擎**：LSM树
- **事务支持**：原子批量写入
- **查询语言**：键值API（无SQL）
- **并发性**：单写多读
- **占用空间**：约250KB库

**Example Usage**:
```cpp
#include <leveldb/db.h>
#include <string>

int main() {
    leveldb::DB* db;
    leveldb::Options options;
    options.create_if_missing = true;
    
    // Optimize for embedded systems
    options.write_buffer_size = 4 * 1024 * 1024;  // 4MB
    options.max_open_files = 100;
    options.block_cache = leveldb::NewLRUCache(8 * 1024 * 1024);  // 8MB cache
    
    leveldb::Status status = leveldb::DB::Open(options, "/data/leveldb", &db);
    
    if (!status.ok()) {
        std::cerr << "Failed to open database: " << status.ToString() << std::endl;
        return 1;
    }
    
    // Write data
    std::string key = "sensor:001:temperature";
    std::string value = "25.5";
    db->Put(leveldb::WriteOptions(), key, value);
    
    // Read data
    std::string read_value;
    status = db->Get(leveldb::ReadOptions(), key, &read_value);
    
    if (status.ok()) {
        std::cout << "Temperature: " << read_value << std::endl;
    }
    
    // Batch write for efficiency
    leveldb::WriteBatch batch;
    batch.Put("sensor:001:humidity", "60.2");
    batch.Put("sensor:001:pressure", "1013.25");
    batch.Delete("old_key");
    db->Write(leveldb::WriteOptions(), &batch);
    
    delete db;
    return 0;
}
```

**示例使用**：
```cpp
#include <leveldb/db.h>
#include <string>

int main() {
    leveldb::DB* db;
    leveldb::Options options;
    options.create_if_missing = true;
    
    // 针对嵌入式系统优化
    options.write_buffer_size = 4 * 1024 * 1024;  // 4MB
    options.max_open_files = 100;
    options.block_cache = leveldb::NewLRUCache(8 * 1024 * 1024);  // 8MB缓存
    
    leveldb::Status status = leveldb::DB::Open(options, "/data/leveldb", &db);
    
    if (!status.ok()) {
        std::cerr << "打开数据库失败: " << status.ToString() << std::endl;
        return 1;
    }
    
    // 写入数据
    std::string key = "sensor:001:temperature";
    std::string value = "25.5";
    db->Put(leveldb::WriteOptions(), key, value);
    
    // 读取数据
    std::string read_value;
    status = db->Get(leveldb::ReadOptions(), key, &read_value);
    
    if (status.ok()) {
        std::cout << "温度: " << read_value << std::endl;
    }
    
    // 批量写入以提高效率
    leveldb::WriteBatch batch;
    batch.Put("sensor:001:humidity", "60.2");
    batch.Put("sensor:001:pressure", "1013.25");
    batch.Delete("old_key");
    db->Write(leveldb::WriteOptions(), &batch);
    
    delete db;
    return 0;
}
```

### 2.3 Berkeley DB

**Description**: Mature embedded database supporting key-value, queue, and B-tree access methods.

**描述**：成熟的嵌入式数据库，支持键值、队列和B树访问方法。

**Architecture**:
- **Storage Engine**: B-tree, Hash, Queue, Recno
- **Transaction Support**: Full ACID
- **Concurrency**: MVCC (Multi-Version Concurrency Control)
- **Footprint**: ~300KB - 500KB

**架构**：
- **存储引擎**：B树、哈希、队列、Recno
- **事务支持**：完整的ACID
- **并发性**：MVCC（多版本并发控制）
- **占用空间**：约300KB - 500KB

**Example Usage**:
```c
#include <db.h>

int main() {
    DB *dbp;
    DBT key, data;
    int ret;
    
    // Create database handle
    ret = db_create(&dbp, NULL, 0);
    
    // Open database
    ret = dbp->open(dbp, NULL, "config.db", NULL, DB_BTREE, DB_CREATE, 0664);
    
    // Prepare key-value pair
    memset(&key, 0, sizeof(DBT));
    memset(&data, 0, sizeof(DBT));
    
    char *key_str = "device_id";
    char *value_str = "ESP32-001";
    
    key.data = key_str;
    key.size = strlen(key_str) + 1;
    data.data = value_str;
    data.size = strlen(value_str) + 1;
    
    // Put data
    ret = dbp->put(dbp, NULL, &key, &data, 0);
    
    // Get data
    memset(&data, 0, sizeof(DBT));
    ret = dbp->get(dbp, NULL, &key, &data, 0);
    
    if (ret == 0) {
        printf("Device ID: %s\n", (char *)data.data);
    }
    
    // Close database
    dbp->close(dbp, 0);
    return 0;
}
```

### 2.4 LMDB (Lightning Memory-Mapped Database)

**Description**: Ultra-fast read-optimized database using memory-mapped files.

**描述**：使用内存映射文件的超快读优化数据库。

**Architecture**:
- **Storage Engine**: B+ tree with copy-on-write
- **Transaction Support**: Full ACID with MVCC
- **Concurrency**: Multiple concurrent readers
- **Footprint**: ~32KB library
- **Performance**: Zero-copy reads

**架构**：
- **存储引擎**：带写时复制的B+树
- **事务支持**：完整的ACID与MVCC
- **并发性**：多个并发读取器
- **占用空间**：约32KB库
- **性能**：零拷贝读取

**Example Usage**:
```c
#include <lmdb.h>

int main() {
    MDB_env *env;
    MDB_dbi dbi;
    MDB_val key, data;
    MDB_txn *txn;
    
    // Create environment
    mdb_env_create(&env);
    mdb_env_set_mapsize(env, 10485760);  // 10MB
    mdb_env_open(env, "./lmdb_data", 0, 0664);
    
    // Begin transaction
    mdb_txn_begin(env, NULL, 0, &txn);
    mdb_dbi_open(txn, NULL, 0, &dbi);
    
    // Write data
    key.mv_data = "temperature";
    key.mv_size = strlen("temperature");
    data.mv_data = "25.5";
    data.mv_size = strlen("25.5");
    
    mdb_put(txn, dbi, &key, &data, 0);
    mdb_txn_commit(txn);
    
    // Read data
    mdb_txn_begin(env, NULL, MDB_RDONLY, &txn);
    mdb_get(txn, dbi, &key, &data);
    printf("Value: %.*s\n", (int)data.mv_size, (char *)data.mv_data);
    mdb_txn_abort(txn);
    
    mdb_dbi_close(env, dbi);
    mdb_env_close(env);
    return 0;
}
```

### 2.5 Comparison Matrix | 对比矩阵

| Feature                 | 特性     | SQLite                   | LevelDB                  | Berkeley DB   | LMDB          |
| ----------------------- | -------- | ------------------------ | ------------------------ | ------------- | ------------- |
| **Query Language**      | 查询语言 | SQL                      | Key-Value API            | Key-Value API | Key-Value API |
| **Storage Engine**      | 存储引擎 | B-tree                   | LSM-tree                 | B-tree/Hash   | B+ tree       |
| **Library Size**        | 库大小   | ~600KB                   | ~250KB                   | ~400KB        | ~32KB         |
| **Write Performance**   | 写性能   | Medium                   | High                     | Medium        | Medium        |
| **Read Performance**    | 读性能   | High                     | Medium                   | High          | Very High     |
| **Memory Usage**        | 内存使用 | Medium                   | High                     | Medium        | Low           |
| **Transaction Support** | 事务支持 | Full ACID                | Batch only               | Full ACID     | Full ACID     |
| **Concurrency**         | 并发性   | Multi-read, Single-write | Multi-read, Single-write | MVCC          | MVCC          |
| **Ideal Use Case**      | 理想用例 | General purpose          | Write-heavy              | Transactional | Read-heavy    |
| **Platform Support**    | 平台支持 | Excellent                | Good                     | Good          | Excellent     |

---

## 3. Architecture and Design | 架构和设计

### 3.1 Storage Engines | 存储引擎

#### 3.1.1 B-tree Storage

**Characteristics**:
- Balanced tree structure
- O(log n) search, insert, delete
- Good for both reads and writes
- Used by: SQLite, Berkeley DB, LMDB

**特性**：
- 平衡树结构
- O(log n)搜索、插入、删除
- 对读写都很好
- 使用者：SQLite、Berkeley DB、LMDB

**Diagram**:
```
        [Root Node]
       /     |     \
   [Node]  [Node]  [Node]
   /  \    /  \    /  \
 [L] [L] [L] [L] [L] [L]  (Leaf nodes contain data)
```

#### 3.1.2 LSM-tree Storage

**Characteristics**:
- Log-Structured Merge tree
- Write-optimized (sequential writes)
- Periodic compaction required
- Used by: LevelDB, RocksDB

**特性**：
- 日志结构合并树
- 写优化（顺序写入）
- 需要定期压缩
- 使用者：LevelDB、RocksDB

**Diagram**:
```
MemTable (RAM) → Immutable MemTable → Level 0 SST Files
                                            ↓ Compaction
                                      Level 1 SST Files
                                            ↓ Compaction
                                      Level N SST Files
```

### 3.2 Memory Management | 内存管理

#### Page Cache Strategy | 页缓存策略

```c
// SQLite page cache configuration for embedded systems
typedef struct EmbeddedCacheConfig {
    int page_size;        // 512, 1024, 2048, 4096 bytes
    int cache_size;       // Number of pages
    int lookaside_slots;  // Small allocation optimization
    int scratch_memory;   // Temp space for sorting
} EmbeddedCacheConfig;

// Low-memory device (64MB RAM)
EmbeddedCacheConfig low_memory = {
    .page_size = 1024,
    .cache_size = 500,      // 500KB cache
    .lookaside_slots = 128,
    .scratch_memory = 8192
};

// Medium device (256MB RAM)
EmbeddedCacheConfig medium_memory = {
    .page_size = 4096,
    .cache_size = 2000,     // 8MB cache
    .lookaside_slots = 512,
    .scratch_memory = 32768
};

// Configure SQLite
void configure_sqlite_memory(sqlite3 *db, EmbeddedCacheConfig *config) {
    char pragma[256];
    
    sprintf(pragma, "PRAGMA page_size=%d;", config->page_size);
    sqlite3_exec(db, pragma, 0, 0, 0);
    
    sprintf(pragma, "PRAGMA cache_size=%d;", config->cache_size);
    sqlite3_exec(db, pragma, 0, 0, 0);
    
    sqlite3_config(SQLITE_CONFIG_LOOKASIDE, config->lookaside_slots, 128);
    sqlite3_config(SQLITE_CONFIG_SCRATCH, scratch_buf, config->scratch_memory, 1);
}
```

**页缓存策略**：
```c
// 嵌入式系统的SQLite页缓存配置
typedef struct EmbeddedCacheConfig {
    int page_size;        // 512, 1024, 2048, 4096字节
    int cache_size;       // 页数
    int lookaside_slots;  // 小分配优化
    int scratch_memory;   // 排序临时空间
} EmbeddedCacheConfig;

// 低内存设备（64MB RAM）
EmbeddedCacheConfig low_memory = {
    .page_size = 1024,
    .cache_size = 500,      // 500KB缓存
    .lookaside_slots = 128,
    .scratch_memory = 8192
};

// 中等设备（256MB RAM）
EmbeddedCacheConfig medium_memory = {
    .page_size = 4096,
    .cache_size = 2000,     // 8MB缓存
    .lookaside_slots = 512,
    .scratch_memory = 32768
};

// 配置SQLite
void configure_sqlite_memory(sqlite3 *db, EmbeddedCacheConfig *config) {
    char pragma[256];
    
    sprintf(pragma, "PRAGMA page_size=%d;", config->page_size);
    sqlite3_exec(db, pragma, 0, 0, 0);
    
    sprintf(pragma, "PRAGMA cache_size=%d;", config->cache_size);
    sqlite3_exec(db, pragma, 0, 0, 0);
    
    sqlite3_config(SQLITE_CONFIG_LOOKASIDE, config->lookaside_slots, 128);
    sqlite3_config(SQLITE_CONFIG_SCRATCH, scratch_buf, config->scratch_memory, 1);
}
```

### 3.3 Transaction Management | 事务管理

#### ACID Properties in Embedded Databases | 嵌入式数据库中的ACID属性

**SQLite WAL Mode**:
```c
// Enable Write-Ahead Logging for better concurrency
sqlite3_exec(db, "PRAGMA journal_mode=WAL;", 0, 0, 0);

// Configure WAL parameters
sqlite3_exec(db, "PRAGMA wal_autocheckpoint=1000;", 0, 0, 0);  // Checkpoint every 1000 pages
sqlite3_exec(db, "PRAGMA wal_checkpoint(TRUNCATE);", 0, 0, 0); // Truncate WAL file

// Transaction example
sqlite3_exec(db, "BEGIN TRANSACTION;", 0, 0, 0);

// Multiple operations
sqlite3_exec(db, "INSERT INTO sensors VALUES(...);", 0, 0, 0);
sqlite3_exec(db, "UPDATE config SET value=...;", 0, 0, 0);

// Commit or rollback
if (success) {
    sqlite3_exec(db, "COMMIT;", 0, 0, 0);
} else {
    sqlite3_exec(db, "ROLLBACK;", 0, 0, 0);
}
```

**SQLite WAL模式**：
```c
// 启用预写日志以获得更好的并发性
sqlite3_exec(db, "PRAGMA journal_mode=WAL;", 0, 0, 0);

// 配置WAL参数
sqlite3_exec(db, "PRAGMA wal_autocheckpoint=1000;", 0, 0, 0);  // 每1000页检查点
sqlite3_exec(db, "PRAGMA wal_checkpoint(TRUNCATE);", 0, 0, 0); // 截断WAL文件

// 事务示例
sqlite3_exec(db, "BEGIN TRANSACTION;", 0, 0, 0);

// 多个操作
sqlite3_exec(db, "INSERT INTO sensors VALUES(...);", 0, 0, 0);
sqlite3_exec(db, "UPDATE config SET value=...;", 0, 0, 0);

// 提交或回滚
if (success) {
    sqlite3_exec(db, "COMMIT;", 0, 0, 0);
} else {
    sqlite3_exec(db, "ROLLBACK;", 0, 0, 0);
}
```

---

## 4. Implementation Guide | 实施指南

### 4.1 Database Selection Decision Tree | 数据库选择决策树

```
START: Select Embedded Database
    |
    ├─ Need SQL queries? ──YES──> SQLite
    |                       |
    |                       └─ Need encryption? ──YES──> SQLCipher
    |
    ├─ Write-heavy workload? ──YES──> LevelDB / RocksDB
    |
    ├─ Read-heavy workload? ──YES──> LMDB
    |
    ├─ Need transactions? ──YES──> Berkeley DB / SQLite
    |
    ├─ Minimal footprint (<50KB)? ──YES──> UnQLite / LMDB
    |
    └─ Mobile platform? ──YES──> Realm / SQLite
```

**开始：选择嵌入式数据库**
```
    |
    ├─ 需要SQL查询？──是──> SQLite
    |                   |
    |                   └─ 需要加密？──是──> SQLCipher
    |
    ├─ 写密集型工作负载？──是──> LevelDB / RocksDB
    |
    ├─ 读密集型工作负载？──是──> LMDB
    |
    ├─ 需要事务？──是──> Berkeley DB / SQLite
    |
    ├─ 最小占用空间（<50KB）？──是──> UnQLite / LMDB
    |
    └─ 移动平台？──是──> Realm / SQLite
```

### 4.2 Schema Design for Embedded Systems | 嵌入式系统的模式设计

#### Principle: Denormalization for Performance | 原则：为性能而非规范化

```sql
-- ❌ Normalized (More JOINs, slower on limited CPU)
CREATE TABLE devices (
    device_id INTEGER PRIMARY KEY,
    device_name TEXT
);

CREATE TABLE sensor_readings (
    reading_id INTEGER PRIMARY KEY,
    device_id INTEGER,
    timestamp INTEGER,
    value REAL,
    FOREIGN KEY (device_id) REFERENCES devices(device_id)
);

-- ✅ Denormalized (Faster, suitable for embedded)
CREATE TABLE sensor_readings (
    reading_id INTEGER PRIMARY KEY,
    device_id INTEGER,
    device_name TEXT,      -- Denormalized
    timestamp INTEGER,
    value REAL,
    INDEX idx_device_time (device_id, timestamp)
);
```

**原则：为性能而非规范化**：
```sql
-- ❌ 规范化（更多JOIN，在有限CPU上更慢）
CREATE TABLE devices (
    device_id INTEGER PRIMARY KEY,
    device_name TEXT
);

CREATE TABLE sensor_readings (
    reading_id INTEGER PRIMARY KEY,
    device_id INTEGER,
    timestamp INTEGER,
    value REAL,
    FOREIGN KEY (device_id) REFERENCES devices(device_id)
);

-- ✅ 非规范化（更快，适合嵌入式）
CREATE TABLE sensor_readings (
    reading_id INTEGER PRIMARY KEY,
    device_id INTEGER,
    device_name TEXT,      -- 非规范化
    timestamp INTEGER,
    value REAL,
    INDEX idx_device_time (device_id, timestamp)
);
```

#### Time-Series Data Pattern | 时间序列数据模式

```c
// Circular buffer table for time-series data (limited storage)
CREATE TABLE sensor_data (
    id INTEGER PRIMARY KEY,
    timestamp INTEGER NOT NULL,
    temperature REAL,
    humidity REAL,
    pressure REAL
);

// Keep only last 10000 readings (auto-cleanup)
CREATE TRIGGER cleanup_old_data 
AFTER INSERT ON sensor_data
WHEN (SELECT COUNT(*) FROM sensor_data) > 10000
BEGIN
    DELETE FROM sensor_data 
    WHERE id IN (
        SELECT id FROM sensor_data 
        ORDER BY timestamp ASC 
        LIMIT 1000
    );
END;
```

**时间序列数据模式**：
```c
// 时间序列数据的循环缓冲区表（有限存储）
CREATE TABLE sensor_data (
    id INTEGER PRIMARY KEY,
    timestamp INTEGER NOT NULL,
    temperature REAL,
    humidity REAL,
    pressure REAL
);

// 仅保留最后10000条读数（自动清理）
CREATE TRIGGER cleanup_old_data 
AFTER INSERT ON sensor_data
WHEN (SELECT COUNT(*) FROM sensor_data) > 10000
BEGIN
    DELETE FROM sensor_data 
    WHERE id IN (
        SELECT id FROM sensor_data 
        ORDER BY timestamp ASC 
        LIMIT 1000
    );
END;
```

### 4.3 API Integration Examples | API集成示例

#### Python with SQLite (IoT Gateway) | Python与SQLite（物联网网关）

```python
import sqlite3
import time
from contextlib import contextmanager

class EmbeddedSensorDB:
    def __init__(self, db_path):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        with self.get_connection() as conn:
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=NORMAL")
            conn.execute("PRAGMA cache_size=2000")
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS sensor_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    sensor_id TEXT NOT NULL,
                    timestamp INTEGER NOT NULL,
                    value REAL NOT NULL,
                    unit TEXT
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_sensor_time 
                ON sensor_data(sensor_id, timestamp)
            """)
    
    @contextmanager
    def get_connection(self):
        conn = sqlite3.connect(self.db_path)
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()
    
    def insert_reading(self, sensor_id, value, unit='°C'):
        with self.get_connection() as conn:
            conn.execute(
                "INSERT INTO sensor_data(sensor_id, timestamp, value, unit) VALUES(?, ?, ?, ?)",
                (sensor_id, int(time.time()), value, unit)
            )
    
    def get_recent_readings(self, sensor_id, limit=100):
        with self.get_connection() as conn:
            cursor = conn.execute(
                "SELECT timestamp, value, unit FROM sensor_data "
                "WHERE sensor_id=? ORDER BY timestamp DESC LIMIT ?",
                (sensor_id, limit)
            )
            return cursor.fetchall()

# Usage
db = EmbeddedSensorDB('/data/sensors.db')
db.insert_reading('temp_001', 25.5, '°C')
readings = db.get_recent_readings('temp_001', limit=10)
```

#### ESP32 with LevelDB (IoT Device) | ESP32与LevelDB（物联网设备）

```cpp
#include <Arduino.h>
#include <leveldb/db.h>
#include <SPIFFS.h>

class ESP32LevelDB {
private:
    leveldb::DB* db;
    leveldb::Options options;
    
public:
    ESP32LevelDB() {
        // Configure for ESP32 (limited RAM: 520KB)
        options.create_if_missing = true;
        options.write_buffer_size = 256 * 1024;  // 256KB
        options.max_open_files = 10;
        options.block_cache = leveldb::NewLRUCache(512 * 1024);  // 512KB cache
        
        // Mount SPIFFS
        if (!SPIFFS.begin(true)) {
            Serial.println("SPIFFS Mount Failed");
            return;
        }
        
        // Open database
        leveldb::Status status = leveldb::DB::Open(options, "/spiffs/leveldb", &db);
        if (!status.ok()) {
            Serial.println("Failed to open LevelDB");
        }
    }
    
    bool put(const String& key, const String& value) {
        leveldb::Status status = db->Put(
            leveldb::WriteOptions(),
            leveldb::Slice(key.c_str()),
            leveldb::Slice(value.c_str())
        );
        return status.ok();
    }
    
    String get(const String& key) {
        std::string value;
        leveldb::Status status = db->Get(
            leveldb::ReadOptions(),
            leveldb::Slice(key.c_str()),
            &value
        );
        return status.ok() ? String(value.c_str()) : String("");
    }
    
    ~ESP32LevelDB() {
        delete db;
    }
};

// Usage in ESP32
ESP32LevelDB kvStore;

void setup() {
    Serial.begin(115200);
    
    // Store sensor reading
    kvStore.put("temp:latest", String(25.5));
    
    // Retrieve value
    String temp = kvStore.get("temp:latest");
    Serial.println("Temperature: " + temp);
}

void loop() {
    // Periodic sensor reading
    float temperature = readTemperatureSensor();
    kvStore.put("temp:latest", String(temperature));
    delay(60000);  // Every minute
}
```

---

## 5. Performance Optimization | 性能优化

### 5.1 Query Optimization | 查询优化

#### Index Strategy for Limited RAM | 有限RAM的索引策略

```sql
-- ✅ Good: Covering index (avoids table lookup)
CREATE INDEX idx_sensor_readings 
ON sensor_data(sensor_id, timestamp) 
INCLUDE (value, unit);

-- Query uses only the index
SELECT timestamp, value, unit 
FROM sensor_data 
WHERE sensor_id = 'temp_001' 
  AND timestamp > 1700000000;

-- ❌ Bad: Multiple separate indexes (wastes memory)
CREATE INDEX idx_sensor ON sensor_data(sensor_id);
CREATE INDEX idx_time ON sensor_data(timestamp);

-- ✅ Good: Composite index
CREATE INDEX idx_sensor_time ON sensor_data(sensor_id, timestamp);
```

**有限RAM的索引策略**：
```sql
-- ✅ 好：覆盖索引（避免表查找）
CREATE INDEX idx_sensor_readings 
ON sensor_data(sensor_id, timestamp) 
INCLUDE (value, unit);

-- 查询仅使用索引
SELECT timestamp, value, unit 
FROM sensor_data 
WHERE sensor_id = 'temp_001' 
  AND timestamp > 1700000000;

-- ❌ 坏：多个单独的索引（浪费内存）
CREATE INDEX idx_sensor ON sensor_data(sensor_id);
CREATE INDEX idx_time ON sensor_data(timestamp);

-- ✅ 好：复合索引
CREATE INDEX idx_sensor_time ON sensor_data(sensor_id, timestamp);
```

### 5.2 Write Amplification Reduction | 减少写放大

#### Batch Writes | 批量写入

```c
// ❌ Bad: Individual writes (high I/O)
for (int i = 0; i < 1000; i++) {
    sqlite3_exec(db, "INSERT INTO sensors VALUES(...)", 0, 0, 0);
}

// ✅ Good: Transaction batching
sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
for (int i = 0; i < 1000; i++) {
    sqlite3_exec(db, "INSERT INTO sensors VALUES(...)", 0, 0, 0);
}
sqlite3_exec(db, "COMMIT", 0, 0, 0);

// ✅ Better: Prepared statements
sqlite3_stmt *stmt;
sqlite3_prepare_v2(db, "INSERT INTO sensors VALUES(?, ?, ?)", -1, &stmt, 0);

sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
for (int i = 0; i < 1000; i++) {
    sqlite3_bind_int(stmt, 1, i);
    sqlite3_bind_int64(stmt, 2, time(NULL));
    sqlite3_bind_double(stmt, 3, sensor_values[i]);
    sqlite3_step(stmt);
    sqlite3_reset(stmt);
}
sqlite3_exec(db, "COMMIT", 0, 0, 0);
sqlite3_finalize(stmt);
```

**批量写入**：
```c
// ❌ 坏：单独写入（高I/O）
for (int i = 0; i < 1000; i++) {
    sqlite3_exec(db, "INSERT INTO sensors VALUES(...)", 0, 0, 0);
}

// ✅ 好：事务批处理
sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
for (int i = 0; i < 1000; i++) {
    sqlite3_exec(db, "INSERT INTO sensors VALUES(...)", 0, 0, 0);
}
sqlite3_exec(db, "COMMIT", 0, 0, 0);

// ✅ 更好：预处理语句
sqlite3_stmt *stmt;
sqlite3_prepare_v2(db, "INSERT INTO sensors VALUES(?, ?, ?)", -1, &stmt, 0);

sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
for (int i = 0; i < 1000; i++) {
    sqlite3_bind_int(stmt, 1, i);
    sqlite3_bind_int64(stmt, 2, time(NULL));
    sqlite3_bind_double(stmt, 3, sensor_values[i]);
    sqlite3_step(stmt);
    sqlite3_reset(stmt);
}
sqlite3_exec(db, "COMMIT", 0, 0, 0);
sqlite3_finalize(stmt);
```

### 5.3 Benchmark Methodologies | 基准测试方法

```c
#include <time.h>

typedef struct BenchmarkResult {
    double insert_time;
    double select_time;
    double update_time;
    int operations;
} BenchmarkResult;

BenchmarkResult benchmark_database(sqlite3 *db, int num_ops) {
    BenchmarkResult result = {0};
    clock_t start, end;
    
    // Benchmark INSERT
    start = clock();
    sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
    for (int i = 0; i < num_ops; i++) {
        char sql[256];
        sprintf(sql, "INSERT INTO test VALUES(%d, %f)", i, (double)i);
        sqlite3_exec(db, sql, 0, 0, 0);
    }
    sqlite3_exec(db, "COMMIT", 0, 0, 0);
    end = clock();
    result.insert_time = ((double)(end - start)) / CLOCKS_PER_SEC;
    
    // Benchmark SELECT
    start = clock();
    for (int i = 0; i < num_ops; i++) {
        char sql[256];
        sprintf(sql, "SELECT * FROM test WHERE id=%d", i);
        sqlite3_exec(db, sql, 0, 0, 0);
    }
    end = clock();
    result.select_time = ((double)(end - start)) / CLOCKS_PER_SEC;
    
    result.operations = num_ops;
    return result;
}

// Print results
void print_benchmark(BenchmarkResult result) {
    printf("Operations: %d\n", result.operations);
    printf("INSERT: %.2f ops/sec\n", result.operations / result.insert_time);
    printf("SELECT: %.2f ops/sec\n", result.operations / result.select_time);
}
```

---

## 6. Data Synchronization | 数据同步

### 6.1 Offline-First Architecture | 离线优先架构

```
┌─────────────────────────────────────────┐
│       Embedded Device (Offline)         │
│  ┌───────────────────────────────────┐  │
│  │     Local Database (SQLite)       │  │
│  │  - Stores all data locally        │  │
│  │  - Works without connectivity     │  │
│  └───────────────┬───────────────────┘  │
│                  │                       │
│  ┌───────────────▼───────────────────┐  │
│  │     Sync Queue                    │  │
│  │  - Pending changes                │  │
│  │  - Conflict markers               │  │
│  └───────────────┬───────────────────┘  │
└──────────────────┼───────────────────────┘
                   │ When connected
                   ▼
┌─────────────────────────────────────────┐
│          Cloud/Server                   │
│  ┌───────────────────────────────────┐  │
│  │    Central Database               │  │
│  │  - Authoritative data store       │  │
│  │  - Conflict resolution            │  │
│  └───────────────────────────────────┘  │
└─────────────────────────────────────────┘
```

### 6.2 Sync Implementation Example | 同步实现示例

```python
import sqlite3
import requests
import json
from datetime import datetime

class DeviceSync:
    def __init__(self, local_db, server_url):
        self.local_db = local_db
        self.server_url = server_url
        self.device_id = self._get_device_id()
        
    def _get_device_id(self):
        # Get unique device identifier
        conn = sqlite3.connect(self.local_db)
        cursor = conn.execute("SELECT value FROM config WHERE key='device_id'")
        row = cursor.fetchone()
        conn.close()
        return row[0] if row else "unknown"
    
    def sync_to_server(self):
        """Upload local changes to server"""
        conn = sqlite3.connect(self.local_db)
        
        # Get pending changes
        cursor = conn.execute("""
            SELECT id, sensor_id, timestamp, value, synced 
            FROM sensor_data 
            WHERE synced = 0
        """)
        pending = cursor.fetchall()
        
        if not pending:
            return True
        
        # Prepare payload
        payload = {
            'device_id': self.device_id,
            'data': [
                {
                    'id': row[0],
                    'sensor_id': row[1],
                    'timestamp': row[2],
                    'value': row[3]
                }
                for row in pending
            ]
        }
        
        try:
            # Send to server
            response = requests.post(
                f"{self.server_url}/api/sync/upload",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                # Mark as synced
                ids = [row[0] for row in pending]
                placeholders = ','.join('?' * len(ids))
                conn.execute(
                    f"UPDATE sensor_data SET synced=1 WHERE id IN ({placeholders})",
                    ids
                )
                conn.commit()
                return True
        except requests.RequestException as e:
            print(f"Sync failed: {e}")
            return False
        finally:
            conn.close()
    
    def sync_from_server(self):
        """Download server changes to local database"""
        try:
            # Get last sync timestamp
            conn = sqlite3.connect(self.local_db)
            cursor = conn.execute("SELECT value FROM config WHERE key='last_sync'")
            last_sync = cursor.fetchone()
            last_sync_time = int(last_sync[0]) if last_sync else 0
            
            # Request server changes
            response = requests.get(
                f"{self.server_url}/api/sync/download",
                params={
                    'device_id': self.device_id,
                    'since': last_sync_time
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Apply changes with conflict resolution
                for record in data['records']:
                    self._apply_record(conn, record)
                
                # Update last sync time
                conn.execute(
                    "INSERT OR REPLACE INTO config(key, value) VALUES('last_sync', ?)",
                    (int(datetime.now().timestamp()),)
                )
                conn.commit()
                return True
                
        except requests.RequestException as e:
            print(f"Download failed: {e}")
            return False
        finally:
            conn.close()
    
    def _apply_record(self, conn, record):
        """Apply server record with Last-Write-Wins conflict resolution"""
        cursor = conn.execute(
            "SELECT timestamp FROM sensor_data WHERE sensor_id=? AND timestamp=?",
            (record['sensor_id'], record['timestamp'])
        )
        existing = cursor.fetchone()
        
        if not existing or existing[0] < record['timestamp']:
            # Server version is newer, update local
            conn.execute("""
                INSERT OR REPLACE INTO sensor_data(sensor_id, timestamp, value, synced)
                VALUES(?, ?, ?, 1)
            """, (record['sensor_id'], record['timestamp'], record['value']))

# Usage
sync = DeviceSync('/data/sensors.db', 'https://api.example.com')

# Periodic sync
import time
while True:
    if is_online():
        sync.sync_to_server()
        sync.sync_from_server()
    time.sleep(300)  # Every 5 minutes
```

### 6.3 Conflict Resolution Strategies | 冲突解决策略

**Last-Write-Wins (LWW) | 最后写入获胜**:
```sql
-- Use timestamp to determine winner
UPDATE sensor_data 
SET value = ?
WHERE sensor_id = ? 
  AND timestamp = ?
  AND synced_timestamp < ?;  -- Only if server version is newer
```

**Custom Application Logic | 自定义应用逻辑**:
```python
def resolve_conflict(local_record, server_record):
    # For sensor data, prefer higher value (safety margin)
    if local_record['value'] > server_record['value']:
        return local_record
    else:
        return server_record
```

---

## 7. Security | 安全性

### 7.1 Encryption at Rest | 静态加密

#### SQLCipher Integration | SQLCipher集成

```c
#include <sqlcipher/sqlite3.h>

int main() {
    sqlite3 *db;
    int rc;
    
    // Open database
    rc = sqlite3_open("encrypted.db", &db);
    
    // Set encryption key
    const char *key = "your-secure-passphrase-here";
    rc = sqlite3_key(db, key, strlen(key));
    
    if (rc != SQLITE_OK) {
        fprintf(stderr, "Failed to set encryption key\n");
        return 1;
    }
    
    // Verify encryption works
    rc = sqlite3_exec(db, "SELECT count(*) FROM sqlite_master", 0, 0, 0);
    
    if (rc != SQLITE_OK) {
        fprintf(stderr, "Database is encrypted with different key\n");
        return 1;
    }
    
    // Use database normally
    sqlite3_exec(db, "CREATE TABLE IF NOT EXISTS secure_data(...)", 0, 0, 0);
    
    sqlite3_close(db);
    return 0;
}
```

#### Custom Encryption for LevelDB | LevelDB的自定义加密

```cpp
#include <leveldb/db.h>
#include <openssl/evp.h>
#include <openssl/aes.h>

class EncryptedValue {
public:
    static std::string encrypt(const std::string& plaintext, const std::string& key) {
        EVP_CIPHER_CTX *ctx = EVP_CIPHER_CTX_new();
        unsigned char iv[16] = {0};  // Initialization vector
        unsigned char ciphertext[1024];
        int len, ciphertext_len;
        
        EVP_EncryptInit_ex(ctx, EVP_aes_256_cbc(), NULL, 
                          (unsigned char*)key.c_str(), iv);
        EVP_EncryptUpdate(ctx, ciphertext, &len, 
                         (unsigned char*)plaintext.c_str(), plaintext.length());
        ciphertext_len = len;
        EVP_EncryptFinal_ex(ctx, ciphertext + len, &len);
        ciphertext_len += len;
        EVP_CIPHER_CTX_free(ctx);
        
        return std::string((char*)ciphertext, ciphertext_len);
    }
    
    static std::string decrypt(const std::string& ciphertext, const std::string& key) {
        // Similar decryption logic
        // ...
    }
};

// Usage with LevelDB
leveldb::DB *db;
std::string encryption_key = "32-byte-encryption-key-here!!";

// Write encrypted
std::string plaintext = "sensitive data";
std::string encrypted = EncryptedValue::encrypt(plaintext, encryption_key);
db->Put(leveldb::WriteOptions(), "key1", encrypted);

// Read and decrypt
std::string value;
db->Get(leveldb::ReadOptions(), "key1", &value);
std::string decrypted = EncryptedValue::decrypt(value, encryption_key);
```

### 7.2 Secure Key Storage | 安全密钥存储

```c
// ESP32 example: Store key in NVS (Non-Volatile Storage)
#include <nvs_flash.h>
#include <nvs.h>

esp_err_t store_encryption_key(const char *key) {
    nvs_handle_t nvs_handle;
    esp_err_t err;
    
    err = nvs_open("storage", NVS_READWRITE, &nvs_handle);
    if (err != ESP_OK) return err;
    
    err = nvs_set_str(nvs_handle, "db_key", key);
    nvs_commit(nvs_handle);
    nvs_close(nvs_handle);
    
    return err;
}

esp_err_t retrieve_encryption_key(char *key, size_t *length) {
    nvs_handle_t nvs_handle;
    esp_err_t err;
    
    err = nvs_open("storage", NVS_READONLY, &nvs_handle);
    if (err != ESP_OK) return err;
    
    err = nvs_get_str(nvs_handle, "db_key", key, length);
    nvs_close(nvs_handle);
    
    return err;
}
```

---

## 8. Power Optimization | 功耗优化

### 8.1 Write Coalescing | 写合并

```c
typedef struct WriteBuffer {
    char keys[100][64];
    char values[100][256];
    int count;
    time_t last_flush;
} WriteBuffer;

WriteBuffer write_buffer = {0};

void buffered_write(const char *key, const char *value) {
    // Add to buffer
    strcpy(write_buffer.keys[write_buffer.count], key);
    strcpy(write_buffer.values[write_buffer.count], value);
    write_buffer.count++;
    
    // Flush if buffer full or timeout
    time_t now = time(NULL);
    if (write_buffer.count >= 100 || (now - write_buffer.last_flush) > 60) {
        flush_buffer_to_db();
    }
}

void flush_buffer_to_db() {
    sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
    
    for (int i = 0; i < write_buffer.count; i++) {
        // Write all buffered data
        char sql[512];
        sprintf(sql, "INSERT INTO data VALUES('%s', '%s')", 
                write_buffer.keys[i], write_buffer.values[i]);
        sqlite3_exec(db, sql, 0, 0, 0);
    }
    
    sqlite3_exec(db, "COMMIT", 0, 0, 0);
    
    write_buffer.count = 0;
    write_buffer.last_flush = time(NULL);
}
```

**写合并**：
```c
typedef struct WriteBuffer {
    char keys[100][64];
    char values[100][256];
    int count;
    time_t last_flush;
} WriteBuffer;

WriteBuffer write_buffer = {0};

void buffered_write(const char *key, const char *value) {
    // 添加到缓冲区
    strcpy(write_buffer.keys[write_buffer.count], key);
    strcpy(write_buffer.values[write_buffer.count], value);
    write_buffer.count++;
    
    // 如果缓冲区满或超时则刷新
    time_t now = time(NULL);
    if (write_buffer.count >= 100 || (now - write_buffer.last_flush) > 60) {
        flush_buffer_to_db();
    }
}

void flush_buffer_to_db() {
    sqlite3_exec(db, "BEGIN TRANSACTION", 0, 0, 0);
    
    for (int i = 0; i < write_buffer.count; i++) {
        // 写入所有缓冲数据
        char sql[512];
        sprintf(sql, "INSERT INTO data VALUES('%s', '%s')", 
                write_buffer.keys[i], write_buffer.values[i]);
        sqlite3_exec(db, sql, 0, 0, 0);
    }
    
    sqlite3_exec(db, "COMMIT", 0, 0, 0);
    
    write_buffer.count = 0;
    write_buffer.last_flush = time(NULL);
}
```

### 8.2 Lazy Persistence | 延迟持久化

```c
// Configure SQLite for power-efficient operation
void configure_power_saving_mode(sqlite3 *db) {
    // Reduce fsync() calls (trades durability for power)
    sqlite3_exec(db, "PRAGMA synchronous=NORMAL", 0, 0, 0);
    
    // Larger WAL checkpoint interval
    sqlite3_exec(db, "PRAGMA wal_autocheckpoint=5000", 0, 0, 0);
    
    // Memory-mapped I/O reduces disk access
    sqlite3_exec(db, "PRAGMA mmap_size=268435456", 0, 0, 0);
    
    // Temp storage in memory
    sqlite3_exec(db, "PRAGMA temp_store=MEMORY", 0, 0, 0);
}
```

**延迟持久化**：
```c
// 配置SQLite以实现节能操作
void configure_power_saving_mode(sqlite3 *db) {
    // 减少fsync()调用（以持久性换功耗）
    sqlite3_exec(db, "PRAGMA synchronous=NORMAL", 0, 0, 0);
    
    // 更大的WAL检查点间隔
    sqlite3_exec(db, "PRAGMA wal_autocheckpoint=5000", 0, 0, 0);
    
    // 内存映射I/O减少磁盘访问
    sqlite3_exec(db, "PRAGMA mmap_size=268435456", 0, 0, 0);
    
    // 临时存储在内存中
    sqlite3_exec(db, "PRAGMA temp_store=MEMORY", 0, 0, 0);
}
```

---

## 9. Platform-Specific Considerations | 平台特定考虑

### 9.1 ARM Cortex-M (Microcontrollers) | ARM Cortex-M（微控制器）

**Constraints | 约束**:
- RAM: 64KB - 512KB
- Flash: 256KB - 2MB
- CPU: 50MHz - 200MHz
- No MMU (Memory Management Unit)

**Recommended Database | 推荐数据库**: UnQLite, Custom key-value store

```c
// Ultra-lightweight key-value store for Cortex-M
#include <string.h>
#include <stdint.h>

#define MAX_RECORDS 100
#define KEY_SIZE 16
#define VALUE_SIZE 64

typedef struct {
    char key[KEY_SIZE];
    char value[VALUE_SIZE];
    uint8_t valid;
} Record;

Record records[MAX_RECORDS];

int kv_put(const char *key, const char *value) {
    // Find existing or empty slot
    for (int i = 0; i < MAX_RECORDS; i++) {
        if (!records[i].valid || strcmp(records[i].key, key) == 0) {
            strncpy(records[i].key, key, KEY_SIZE - 1);
            strncpy(records[i].value, value, VALUE_SIZE - 1);
            records[i].valid = 1;
            return 0;
        }
    }
    return -1;  // Storage full
}

const char* kv_get(const char *key) {
    for (int i = 0; i < MAX_RECORDS; i++) {
        if (records[i].valid && strcmp(records[i].key, key) == 0) {
            return records[i].value;
        }
    }
    return NULL;
}
```

### 9.2 ESP32 (IoT Platform) | ESP32（物联网平台）

**Specifications | 规格**:
- RAM: 520KB SRAM
- Flash: 4MB - 16MB
- CPU: Dual-core 240MHz
- Wi-Fi + Bluetooth

**Recommended Database | 推荐数据库**: SQLite (with optimizations), LevelDB

```cpp
// ESP32-optimized SQLite configuration
#include <sqlite3.h>
#include <SPIFFS.h>

void setup_esp32_database() {
    // Mount SPIFFS
    if (!SPIFFS.begin(true)) {
        Serial.println("SPIFFS Mount Failed");
        return;
    }
    
    sqlite3 *db;
    int rc = sqlite3_open("/spiffs/sensor.db", &db);
    
    if (rc) {
        Serial.printf("Can't open database: %s\n", sqlite3_errmsg(db));
        return;
    }
    
    // ESP32 optimization
    sqlite3_exec(db, "PRAGMA journal_mode=MEMORY", 0, 0, 0);  // Journal in RAM
    sqlite3_exec(db, "PRAGMA cache_size=1000", 0, 0, 0);      // 1000 pages (~4MB)
    sqlite3_exec(db, "PRAGMA page_size=4096", 0, 0, 0);
    sqlite3_exec(db, "PRAGMA synchronous=NORMAL", 0, 0, 0);
    
    // Create table
    sqlite3_exec(db, 
        "CREATE TABLE IF NOT EXISTS readings("
        "id INTEGER PRIMARY KEY,"
        "sensor TEXT,"
        "value REAL,"
        "timestamp INTEGER)", 0, 0, 0);
}
```

### 9.3 Raspberry Pi (Single-Board Computer) | Raspberry Pi（单板计算机）

**Specifications | 规格**:
- RAM: 1GB - 8GB
- Storage: 16GB - 256GB SD card
- CPU: Quad-core 1.5GHz ARM Cortex-A72
- Full Linux OS

**Recommended Database | 推荐数据库**: SQLite, PostgreSQL (for larger projects)

```python
# Raspberry Pi IoT gateway with SQLite
import sqlite3
import RPi.GPIO as GPIO
import time

class RaspberryPiSensorLogger:
    def __init__(self, db_path='/home/pi/sensors.db'):
        self.conn = sqlite3.connect(db_path)
        self._init_database()
        self._init_gpio()
    
    def _init_database(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS sensor_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                sensor_type TEXT NOT NULL,
                gpio_pin INTEGER,
                value REAL,
                timestamp INTEGER DEFAULT (strftime('%s', 'now'))
            )
        """)
        
        # Create index for time-based queries
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_timestamp 
            ON sensor_logs(timestamp)
        """)
        self.conn.commit()
    
    def _init_gpio(self):
        GPIO.setmode(GPIO.BCM)
        # Configure DHT22 sensor on GPIO 4
        self.dht_pin = 4
    
    def log_sensor_reading(self, sensor_type, gpio_pin, value):
        self.conn.execute(
            "INSERT INTO sensor_logs(sensor_type, gpio_pin, value) VALUES(?, ?, ?)",
            (sensor_type, gpio_pin, value)
        )
        self.conn.commit()
    
    def get_recent_readings(self, hours=24):
        cutoff = int(time.time()) - (hours * 3600)
        cursor = self.conn.execute(
            "SELECT * FROM sensor_logs WHERE timestamp > ? ORDER BY timestamp DESC",
            (cutoff,)
        )
        return cursor.fetchall()

# Usage
logger = RaspberryPiSensorLogger()

# Main loop
while True:
    # Read temperature and humidity from DHT22
    temperature = read_dht22_temperature(4)
    humidity = read_dht22_humidity(4)
    
    logger.log_sensor_reading('DHT22_TEMP', 4, temperature)
    logger.log_sensor_reading('DHT22_HUM', 4, humidity)
    
    time.sleep(60)  # Log every minute
```

---

## 10. Real-World Examples | 真实世界示例

### 10.1 IoT Sensor Data Logging | 物联网传感器数据记录

**Scenario | 场景**: Environmental monitoring station with multiple sensors

**环境监测站，配备多个传感器**

```c
// ESP32 multi-sensor data logger
#include <sqlite3.h>
#include <DHT.h>
#include <Wire.h>
#include <Adafruit_BMP280.h>

#define DHT_PIN 4
#define DHT_TYPE DHT22

DHT dht(DHT_PIN, DHT_TYPE);
Adafruit_BMP280 bmp;
sqlite3 *db;

void setup() {
    Serial.begin(115200);
    
    // Initialize sensors
    dht.begin();
    bmp.begin();
    
    // Open database
    sqlite3_open("/spiffs/weather.db", &db);
    
    // Create tables
    sqlite3_exec(db, 
        "CREATE TABLE IF NOT EXISTS weather_data("
        "id INTEGER PRIMARY KEY AUTOINCREMENT,"
        "timestamp INTEGER,"
        "temperature REAL,"
        "humidity REAL,"
        "pressure REAL,"
        "altitude REAL"
        ");", 0, 0, 0);
    
    // Optimize for embedded system
    sqlite3_exec(db, "PRAGMA journal_mode=WAL;", 0, 0, 0);
    sqlite3_exec(db, "PRAGMA synchronous=NORMAL;", 0, 0, 0);
    sqlite3_exec(db, "PRAGMA cache_size=1000;", 0, 0, 0);
}

void loop() {
    // Read sensors
    float temp = dht.readTemperature();
    float hum = dht.readHumidity();
    float pressure = bmp.readPressure() / 100.0F;  // hPa
    float altitude = bmp.readAltitude(1013.25);     // meters
    
    // Insert into database
    char sql[256];
    sprintf(sql, 
        "INSERT INTO weather_data(timestamp, temperature, humidity, pressure, altitude) "
        "VALUES(%ld, %.2f, %.2f, %.2f, %.2f);",
        time(NULL), temp, hum, pressure, altitude
    );
    
    int rc = sqlite3_exec(db, sql, 0, 0, 0);
    
    if (rc == SQLITE_OK) {
        Serial.println("Data logged successfully");
    } else {
        Serial.printf("SQL error: %s\n", sqlite3_errmsg(db));
    }
    
    // Log every 5 minutes
    delay(300000);
}
```

### 10.2 Automotive ECU Data Storage | 汽车ECU数据存储

**Scenario | 场景**: Black box recorder for automotive diagnostics

**汽车诊断黑匣子记录器**

```cpp
// Automotive data recorder using LevelDB
#include <leveldb/db.h>
#include <CAN.h>  // CAN bus library

class AutomotiveDataRecorder {
private:
    leveldb::DB* db;
    
public:
    AutomotiveDataRecorder() {
        leveldb::Options options;
        options.create_if_missing = true;
        options.write_buffer_size = 1024 * 1024;  // 1MB
        options.max_open_files = 50;
        
        leveldb::Status status = leveldb::DB::Open(
            options, 
            "/data/automotive_logs", 
            &db
        );
    }
    
    void log_can_message(uint32_t can_id, const uint8_t* data, uint8_t len) {
        // Create key with timestamp and CAN ID
        char key[32];
        uint64_t timestamp = micros();
        snprintf(key, sizeof(key), "%llu:%08X", timestamp, can_id);
        
        // Store CAN data
        leveldb::Slice key_slice(key);
        leveldb::Slice value_slice((char*)data, len);
        
        db->Put(leveldb::WriteOptions(), key_slice, value_slice);
    }
    
    void log_obd_data(uint16_t pid, uint32_t value) {
        char key[32], val[16];
        snprintf(key, sizeof(key), "OBD:%04X:%llu", pid, millis());
        snprintf(val, sizeof(val), "%lu", value);
        
        db->Put(leveldb::WriteOptions(), key, val);
    }
    
    std::vector<std::string> get_recent_logs(uint32_t duration_ms) {
        std::vector<std::string> logs;
        uint64_t cutoff = millis() - duration_ms;
        
        leveldb::Iterator* it = db->NewIterator(leveldb::ReadOptions());
        for (it->SeekToFirst(); it->Valid(); it->Next()) {
            // Parse timestamp from key
            uint64_t ts;
            sscanf(it->key().ToString().c_str(), "%llu", &ts);
            
            if (ts > cutoff) {
                logs.push_back(it->value().ToString());
            }
        }
        delete it;
        return logs;
    }
};

// Usage in automotive ECU
AutomotiveDataRecorder recorder;

void setup() {
    CAN.begin(500E3);  // 500 kbps CAN bus
}

void loop() {
    // Monitor CAN bus
    int packetSize = CAN.parsePacket();
    
    if (packetSize) {
        uint32_t can_id = CAN.packetId();
        uint8_t data[8];
        int len = 0;
        
        while (CAN.available() && len < 8) {
            data[len++] = CAN.read();
        }
        
        recorder.log_can_message(can_id, data, len);
    }
    
    // Log OBD-II data periodically
    static unsigned long last_obd = 0;
    if (millis() - last_obd > 1000) {
        // Example: Engine RPM (PID 0x0C)
        uint32_t rpm = read_obd_pid(0x0C);
        recorder.log_obd_data(0x0C, rpm);
        last_obd = millis();
    }
}
```

### 10.3 Medical Device Patient Records | 医疗设备患者记录

**Scenario | 场景**: Portable ECG monitor with local storage

**便携式心电图监护仪，带本地存储**

```c
#include <sqlite3.h>
#include <time.h>

typedef struct ECGReading {
    int patient_id;
    uint64_t timestamp;
    int16_t samples[500];  // 500 samples at 500Hz = 1 second
    int sample_count;
    float heart_rate;
} ECGReading;

class MedicalDeviceDB {
private:
    sqlite3 *db;
    sqlite3_stmt *insert_stmt;
    
public:
    MedicalDeviceDB(const char *db_path) {
        sqlite3_open(db_path, &db);
        
        // Enable encryption for HIPAA compliance
        const char *key = get_device_encryption_key();
        sqlite3_key(db, key, strlen(key));
        
        // Create schema
        sqlite3_exec(db, 
            "CREATE TABLE IF NOT EXISTS ecg_readings("
            "id INTEGER PRIMARY KEY AUTOINCREMENT,"
            "patient_id INTEGER NOT NULL,"
            "timestamp INTEGER NOT NULL,"
            "waveform BLOB NOT NULL,"
            "heart_rate REAL,"
            "sample_rate INTEGER,"
            "duration_ms INTEGER"
            ");", 0, 0, 0);
        
        // HIPAA audit logging
        sqlite3_exec(db,
            "CREATE TABLE IF NOT EXISTS access_log("
            "id INTEGER PRIMARY KEY AUTOINCREMENT,"
            "timestamp INTEGER,"
            "user_id TEXT,"
            "action TEXT,"
            "patient_id INTEGER"
            ");", 0, 0, 0);
        
        // Prepare insert statement
        sqlite3_prepare_v2(db,
            "INSERT INTO ecg_readings(patient_id, timestamp, waveform, "
            "heart_rate, sample_rate, duration_ms) VALUES(?, ?, ?, ?, ?, ?)",
            -1, &insert_stmt, 0);
    }
    
    void store_ecg_reading(const ECGReading *reading) {
        // Bind parameters
        sqlite3_bind_int(insert_stmt, 1, reading->patient_id);
        sqlite3_bind_int64(insert_stmt, 2, reading->timestamp);
        sqlite3_bind_blob(insert_stmt, 3, reading->samples, 
                         reading->sample_count * sizeof(int16_t), SQLITE_STATIC);
        sqlite3_bind_double(insert_stmt, 4, reading->heart_rate);
        sqlite3_bind_int(insert_stmt, 5, 500);  // 500 Hz
        sqlite3_bind_int(insert_stmt, 6, 1000); // 1 second
        
        // Execute
        sqlite3_step(insert_stmt);
        sqlite3_reset(insert_stmt);
        
        // HIPAA audit log
        log_access("STORE_ECG", reading->patient_id);
    }
    
    void log_access(const char *action, int patient_id) {
        char sql[256];
        snprintf(sql, sizeof(sql),
            "INSERT INTO access_log(timestamp, user_id, action, patient_id) "
            "VALUES(%ld, '%s', '%s', %d)",
            time(NULL), get_current_user(), action, patient_id);
        sqlite3_exec(db, sql, 0, 0, 0);
    }
};
```

### 10.4 Smart Home Device Configuration | 智能家居设备配置

```python
import sqlite3
import json
from typing import Dict, Any

class SmartHomeConfigDB:
    def __init__(self, db_path='/data/smart_home.db'):
        self.conn = sqlite3.connect(db_path)
        self._init_schema()
    
    def _init_schema(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS devices (
                device_id TEXT PRIMARY KEY,
                device_type TEXT NOT NULL,
                room TEXT,
                config JSON,
                last_seen INTEGER,
                is_online INTEGER DEFAULT 0
            )
        """)
        
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS automation_rules (
                rule_id INTEGER PRIMARY KEY AUTOINCREMENT,
                rule_name TEXT,
                trigger_device TEXT,
                trigger_condition TEXT,
                action_device TEXT,
                action TEXT,
                enabled INTEGER DEFAULT 1
            )
        """)
        self.conn.commit()
    
    def register_device(self, device_id: str, device_type: str, 
                       room: str, config: Dict[str, Any]):
        self.conn.execute(
            "INSERT OR REPLACE INTO devices(device_id, device_type, room, config, last_seen, is_online) "
            "VALUES(?, ?, ?, ?, ?, ?)",
            (device_id, device_type, room, json.dumps(config), int(time.time()), 1)
        )
        self.conn.commit()
    
    def get_device_config(self, device_id: str) -> Dict[str, Any]:
        cursor = self.conn.execute(
            "SELECT config FROM devices WHERE device_id = ?",
            (device_id,)
        )
        row = cursor.fetchone()
        return json.loads(row[0]) if row else None
    
    def add_automation_rule(self, rule_name: str, trigger_device: str,
                           trigger_condition: str, action_device: str, action: str):
        self.conn.execute(
            "INSERT INTO automation_rules(rule_name, trigger_device, trigger_condition, "
            "action_device, action) VALUES(?, ?, ?, ?, ?)",
            (rule_name, trigger_device, trigger_condition, action_device, action)
        )
        self.conn.commit()
    
    def get_active_rules(self):
        cursor = self.conn.execute(
            "SELECT * FROM automation_rules WHERE enabled = 1"
        )
        return cursor.fetchall()

# Usage
db = SmartHomeConfigDB()

# Register smart light
db.register_device(
    device_id='light_001',
    device_type='smart_bulb',
    room='living_room',
    config={
        'brightness': 80,
        'color_temp': 3000,
        'supports_rgb': True
    }
)

# Add automation rule
db.add_automation_rule(
    rule_name='Motion activated light',
    trigger_device='motion_sensor_001',
    trigger_condition='motion_detected',
    action_device='light_001',
    action='turn_on'
)
```

---

## 11. Testing and Debugging | 测试和调试

### 11.1 Unit Testing | 单元测试

```c
// Unity test framework for embedded databases
#include "unity.h"
#include <sqlite3.h>

sqlite3 *test_db;

void setUp(void) {
    // Create in-memory database for testing
    sqlite3_open(":memory:", &test_db);
    sqlite3_exec(test_db, 
        "CREATE TABLE test(id INTEGER PRIMARY KEY, value TEXT)", 0, 0, 0);
}

void tearDown(void) {
    sqlite3_close(test_db);
}

void test_insert_and_select(void) {
    // Test INSERT
    int rc = sqlite3_exec(test_db, 
        "INSERT INTO test(value) VALUES('test_data')", 0, 0, 0);
    TEST_ASSERT_EQUAL(SQLITE_OK, rc);
    
    // Test SELECT
    sqlite3_stmt *stmt;
    sqlite3_prepare_v2(test_db, "SELECT value FROM test WHERE id=1", -1, &stmt, 0);
    sqlite3_step(stmt);
    
    const char *value = (const char*)sqlite3_column_text(stmt, 0);
    TEST_ASSERT_EQUAL_STRING("test_data", value);
    
    sqlite3_finalize(stmt);
}

void test_transaction_rollback(void) {
    sqlite3_exec(test_db, "BEGIN TRANSACTION", 0, 0, 0);
    sqlite3_exec(test_db, "INSERT INTO test(value) VALUES('rollback_test')", 0, 0, 0);
    sqlite3_exec(test_db, "ROLLBACK", 0, 0, 0);
    
    // Verify data was not committed
    sqlite3_stmt *stmt;
    sqlite3_prepare_v2(test_db, "SELECT COUNT(*) FROM test", -1, &stmt, 0);
    sqlite3_step(stmt);
    
    int count = sqlite3_column_int(stmt, 0);
    TEST_ASSERT_EQUAL(0, count);
    
    sqlite3_finalize(stmt);
}

int main(void) {
    UNITY_BEGIN();
    RUN_TEST(test_insert_and_select);
    RUN_TEST(test_transaction_rollback);
    return UNITY_END();
}
```

### 11.2 Memory Profiling | 内存分析

```bash
# Valgrind memory leak detection
valgrind --leak-check=full --show-leak-kinds=all ./embedded_db_app

# Output example:
# ==12345== HEAP SUMMARY:
# ==12345==     in use at exit: 0 bytes in 0 blocks
# ==12345==   total heap usage: 1,245 allocs, 1,245 frees, 512,340 bytes allocated
```

```c
// Custom memory tracking for embedded systems
#include <stdlib.h>

static size_t total_allocated = 0;
static size_t peak_allocated = 0;

void* tracked_malloc(size_t size) {
    void *ptr = malloc(size + sizeof(size_t));
    if (ptr) {
        *(size_t*)ptr = size;
        total_allocated += size;
        if (total_allocated > peak_allocated) {
            peak_allocated = total_allocated;
        }
        return (char*)ptr + sizeof(size_t);
    }
    return NULL;
}

void tracked_free(void *ptr) {
    if (ptr) {
        size_t size = *((size_t*)((char*)ptr - sizeof(size_t)));
        total_allocated -= size;
        free((char*)ptr - sizeof(size_t));
    }
}

void print_memory_stats(void) {
    printf("Current allocated: %zu bytes\n", total_allocated);
    printf("Peak allocated: %zu bytes\n", peak_allocated);
}
```

### 11.3 Power Profiling | 功耗分析

```python
# Python script for analyzing power consumption logs
import pandas as pd
import matplotlib.pyplot as plt

# Load power measurement data
data = pd.read_csv('power_log.csv')

# Calculate statistics
idle_power = data[data['state'] == 'idle']['power_mw'].mean()
write_power = data[data['state'] == 'writing']['power_mw'].mean()
read_power = data[data['state'] == 'reading']['power_mw'].mean()

print(f"Idle: {idle_power:.2f} mW")
print(f"Writing: {write_power:.2f} mW")
print(f"Reading: {read_power:.2f} mW")

# Calculate battery life estimate
battery_capacity_mah = 2000
average_current_ma = (write_power + read_power) / 2 / 3.3  # Assuming 3.3V
battery_life_hours = battery_capacity_mah / average_current_ma

print(f"Estimated battery life: {battery_life_hours:.1f} hours")

# Plot power consumption over time
plt.figure(figsize=(12, 6))
plt.plot(data['timestamp'], data['power_mw'])
plt.xlabel('Time (s)')
plt.ylabel('Power (mW)')
plt.title('Database Power Consumption Profile')
plt.grid(True)
plt.savefig('power_profile.png')
```

---

## 12. Best Practices | 最佳实践

### 12.1 Resource Budgeting | 资源预算

```c
// Resource budget configuration
typedef struct ResourceBudget {
    size_t max_memory_bytes;      // Maximum RAM usage
    size_t max_storage_bytes;     // Maximum storage usage
    uint32_t max_power_mw;        // Maximum power consumption
    uint32_t max_write_ops_sec;   // Write operations per second
} ResourceBudget;

// Low-power IoT device budget
ResourceBudget iot_device_budget = {
    .max_memory_bytes = 512 * 1024,    // 512 KB RAM
    .max_storage_bytes = 16 * 1024 * 1024,  // 16 MB flash
    .max_power_mw = 50,                // 50 mW average
    .max_write_ops_sec = 10            // 10 writes/sec max
};

// Configure database to meet budget
void configure_for_budget(sqlite3 *db, ResourceBudget *budget) {
    // Calculate cache size (use 30% of available RAM)
    int cache_pages = (budget->max_memory_bytes * 0.3) / 4096;
    char pragma[64];
    
    sprintf(pragma, "PRAGMA cache_size=%d", cache_pages);
    sqlite3_exec(db, pragma, 0, 0, 0);
    
    // For low write rate, use less aggressive syncing
    if (budget->max_write_ops_sec < 50) {
        sqlite3_exec(db, "PRAGMA synchronous=NORMAL", 0, 0, 0);
    }
    
    // Storage size management
    sprintf(pragma, "PRAGMA max_page_count=%zu", 
            budget->max_storage_bytes / 4096);
    sqlite3_exec(db, pragma, 0, 0, 0);
}
```

### 12.2 Error Handling | 错误处理

```c
#include <sqlite3.h>
#include <syslog.h>

typedef enum {
    DB_SUCCESS = 0,
    DB_ERROR_OPEN,
    DB_ERROR_QUERY,
    DB_ERROR_CORRUPT,
    DB_ERROR_FULL,
    DB_ERROR_MEMORY
} DBErrorCode;

DBErrorCode safe_db_execute(sqlite3 *db, const char *sql) {
    int rc = sqlite3_exec(db, sql, 0, 0, 0);
    
    switch (rc) {
        case SQLITE_OK:
            return DB_SUCCESS;
        
        case SQLITE_CORRUPT:
            syslog(LOG_ERR, "Database corruption detected");
            // Attempt recovery
            sqlite3_exec(db, "PRAGMA integrity_check", 0, 0, 0);
            return DB_ERROR_CORRUPT;
        
        case SQLITE_FULL:
            syslog(LOG_WARNING, "Database storage full");
            // Trigger cleanup
            cleanup_old_records(db);
            return DB_ERROR_FULL;
        
        case SQLITE_NOMEM:
            syslog(LOG_ERR, "Out of memory");
            // Reduce cache size
            sqlite3_exec(db, "PRAGMA cache_size=100", 0, 0, 0);
            return DB_ERROR_MEMORY;
        
        default:
            syslog(LOG_ERR, "Database error: %s", sqlite3_errmsg(db));
            return DB_ERROR_QUERY;
    }
}

void cleanup_old_records(sqlite3 *db) {
    // Delete records older than 30 days
    char sql[256];
    time_t cutoff = time(NULL) - (30 * 24 * 3600);
    sprintf(sql, "DELETE FROM sensor_data WHERE timestamp < %ld", cutoff);
    sqlite3_exec(db, sql, 0, 0, 0);
    
    // VACUUM to reclaim space
    sqlite3_exec(db, "VACUUM", 0, 0, 0);
}
```

### 12.3 Database Migration | 数据库迁移

```c
// Version-based schema migration
#define SCHEMA_VERSION 3

int get_current_schema_version(sqlite3 *db) {
    sqlite3_stmt *stmt;
    int version = 0;
    
    int rc = sqlite3_prepare_v2(db, 
        "SELECT value FROM schema_info WHERE key='version'", -1, &stmt, 0);
    
    if (rc == SQLITE_OK && sqlite3_step(stmt) == SQLITE_ROW) {
        version = sqlite3_column_int(stmt, 0);
    }
    sqlite3_finalize(stmt);
    
    return version;
}

void migrate_database(sqlite3 *db) {
    int current_version = get_current_schema_version(db);
    
    if (current_version < 1) {
        // Initial schema
        sqlite3_exec(db,
            "CREATE TABLE schema_info(key TEXT PRIMARY KEY, value TEXT);",
            0, 0, 0);
        sqlite3_exec(db,
            "INSERT INTO schema_info VALUES('version', '1');",
            0, 0, 0);
        current_version = 1;
    }
    
    if (current_version < 2) {
        // Migration to version 2: Add index
        sqlite3_exec(db,
            "CREATE INDEX idx_sensor_time ON sensor_data(sensor_id, timestamp);",
            0, 0, 0);
        sqlite3_exec(db,
            "UPDATE schema_info SET value='2' WHERE key='version';",
            0, 0, 0);
        current_version = 2;
    }
    
    if (current_version < 3) {
        // Migration to version 3: Add new column
        sqlite3_exec(db,
            "ALTER TABLE sensor_data ADD COLUMN device_id TEXT;",
            0, 0, 0);
        sqlite3_exec(db,
            "UPDATE schema_info SET value='3' WHERE key='version';",
            0, 0, 0);
        current_version = 3;
    }
}
```

### 12.4 Logging in Production | 生产环境日志

```c
#include <stdarg.h>
#include <stdio.h>
#include <time.h>

typedef enum {
    LOG_DEBUG,
    LOG_INFO,
    LOG_WARNING,
    LOG_ERROR
} LogLevel;

static LogLevel min_log_level = LOG_INFO;
static FILE *log_file = NULL;

void db_log_init(const char *log_path, LogLevel level) {
    log_file = fopen(log_path, "a");
    min_log_level = level;
}

void db_log(LogLevel level, const char *format, ...) {
    if (level < min_log_level || !log_file) return;
    
    const char *level_str[] = {"DEBUG", "INFO", "WARN", "ERROR"};
    
    // Timestamp
    time_t now = time(NULL);
    char timestamp[32];
    strftime(timestamp, sizeof(timestamp), "%Y-%m-%d %H:%M:%S", 
             localtime(&now));
    
    // Write log
    fprintf(log_file, "[%s] [%s] ", timestamp, level_str[level]);
    
    va_list args;
    va_start(args, format);
    vfprintf(log_file, format, args);
    va_end(args);
    
    fprintf(log_file, "\n");
    fflush(log_file);
}

// Usage
db_log_init("/var/log/embedded_db.log", LOG_INFO);
db_log(LOG_INFO, "Database opened: %s", db_path);
db_log(LOG_WARNING, "Cache size reduced due to memory pressure");
db_log(LOG_ERROR, "Failed to write data: %s", sqlite3_errmsg(db));
```

---

## Conclusion | 结论

**Embedded databases** are critical components in modern IoT, mobile, automotive, and industrial systems. Choosing the right database and optimizing it for resource-constrained environments requires careful consideration of:

**嵌入式数据库**是现代物联网、移动、汽车和工业系统中的关键组件。为资源受限环境选择合适的数据库并进行优化需要仔细考虑：

**Key Takeaways | 关键要点**:

1. **Database Selection | 数据库选择**:
   - SQLite for general-purpose SQL needs
   - LevelDB/RocksDB for write-heavy workloads
   - LMDB for read-optimized scenarios
   - Custom solutions for ultra-constrained microcontrollers
   
   - SQLite用于通用SQL需求
   - LevelDB/RocksDB用于写密集型工作负载
   - LMDB用于读优化场景
   - 超受限微控制器的自定义解决方案

2. **Optimization Priorities | 优化优先级**:
   - Memory management and cache tuning
   - Index design for limited resources
   - Batch operations to reduce I/O
   - Power-aware configurations
   
   - 内存管理和缓存调优
   - 有限资源的索引设计
   - 批量操作以减少I/O
   - 功耗感知配置

3. **Reliability | 可靠性**:
   - ACID transactions where needed
   - Crash recovery mechanisms
   - Data synchronization with cloud
   - Regular backup strategies
   
   - 在需要时使用ACID事务
   - 崩溃恢复机制
   - 与云的数据同步
   - 定期备份策略

4. **Security | 安全性**:
   - Encryption for sensitive data
   - Secure key management
   - Access audit logging
   - Compliance with regulations (HIPAA, GDPR)
   
   - 敏感数据加密
   - 安全密钥管理
   - 访问审计日志
   - 符合法规（HIPAA、GDPR）

5. **Testing | 测试**:
   - Unit testing on target hardware
   - Memory and power profiling
   - Stress testing under constraints
   - Field testing with real workloads
   
   - 在目标硬件上进行单元测试
   - 内存和功耗分析
   - 约束条件下的压力测试
   - 真实工作负载的现场测试

**Future Trends | 未来趋势**:
- Edge AI integration with on-device databases
- 5G-enabled ultra-low latency sync
- Energy harvesting-aware database operations
- Blockchain integration for data integrity

- 边缘AI与设备上数据库的集成
- 5G支持的超低延迟同步
- 能量收集感知的数据库操作
- 区块链集成以确保数据完整性

---

## References | 参考资料

- SQLite Official Documentation: https://www.sqlite.org/docs.html
- LevelDB GitHub: https://github.com/google/leveldb
- Berkeley DB Documentation: https://docs.oracle.com/cd/E17276_01/html/index.html
- LMDB Technical Paper: http://www.lmdb.tech/doc/
- Embedded Systems Design Patterns
- IoT Database Best Practices
- ARM Cortex-M Programming Guide

**End of Document | 文档结束